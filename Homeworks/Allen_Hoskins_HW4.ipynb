{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transfer Learning Homework \n",
    "\n",
    "Below you see a tutorial from Keras on using transfer learning. They train their models on half  the MNIST dataset digits (i.e. digits 0-4) and “transfer” the model to the second half (i.e, digits 5-9). \n",
    "\n",
    "Your homework is to train on all digits and make your own handwritten data set of the 5 characters {A, B, C, D, E}  and “transfer” your MNIST trained model over to the dataset you created. In other words, train on the full MNIST datasets (i.e. digits 0-9) and transfer on the {A, B, C, D, E} image dataset. \n",
    "\n",
    "Please do not use any other data resources from the web such as the emnist dataset. Figuring out the challenges of making your own handwritten character dataset is part of the exercise for this homework!   \n",
    "\n",
    "Include the images you generated as part of your submission. Include any code used for the character image preprocessing. In a README file include details on your data generation process.\n",
    "\n",
    "Code source: https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_transfer_cnn.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,  Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "now = datetime.datetime.now\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "def train_model(model, train, test, num_classes):\n",
    "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
    "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=input_shape),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]\n",
    "\n",
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "# train model for 5-digit classification [0..4]\n",
    "train_model(model,\n",
    "            (x_train_lt5, y_train_lt5),\n",
    "            (x_test_lt5, y_test_lt5), num_classes)\n",
    "\n",
    "# freeze feature layers and rebuild model\n",
    "for l in feature_layers:\n",
    "    l.trainable = False\n",
    "\n",
    "# transfer step: train dense layers for new classification task [5..9]\n",
    "train_model(model,\n",
    "            (x_train_gte5, y_train_gte5),\n",
    "            (x_test_gte5, y_test_gte5), num_classes)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ML1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3121556d4473c412f0595648b5a85484255f0878c67145bad0a6023335311018"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
